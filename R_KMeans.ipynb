{"cells":[{"cell_type":"markdown","source":["## K-Means Clustering of Stack Overflow\n####Import pyspark libraries\n####Import R Answers csv"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.clustering import KMeans\nfrom pyspark.ml.feature import VectorAssembler"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["%fs ls /FileStore/tables/R_Answers.csv"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["#Data is R_Answers\ndata = spark.sql(\"SELECT * FROM R_Answers_csv\") #df_data_1\n\ndata1 = data.dropna()\ndata1.show(5)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["data1.printSchema()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# Data2 is R_Tags\ndata2=spark.sql(\"SELECT * FROM R_Tags_csv\") \ndata2.show(5)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["#Join Answers and Tags\ndata3=data2.join(data1, data1.ParentId==data2.Id)\ndata3.show(5)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["## StringIndexer"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer\n \nindexer = StringIndexer(inputCol=\"IsAcceptedAnswer\", outputCol=\"IsAcceptedAnswer_Indexed\").fit(data3)\nindexed_data1 = indexer.transform(data3)\nindexed_data1.drop(\"Id\").show()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["assembler = VectorAssembler(inputCols = [ \"OwnerUserId\", \"ParentId\", \"Score\",\"IsAcceptedAnswer_Indexed\"], outputCol=\"features\")\ntrain = assembler.transform(indexed_data1)\n\nknum = 2\n# Make sure to set [predictionCol=\"prediction\"]\nkmeans = KMeans(featuresCol=assembler.getOutputCol(), predictionCol=\"prediction\", k=knum, seed=0)\nmodel = kmeans.fit(train)\nprint \"Model Created!\""],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["## Visualize Predictions\n###Is Accepted Answer"],"metadata":{}},{"cell_type":"code","source":["# data set does not need to be divided to train and test\npredictions = model.transform(train)\npredictions.groupBy(\"prediction\").count().orderBy(\"prediction\").show()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["predictions.select(\"features\", \"prediction\").show(5)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["predictions.select(\"features\", \"prediction\").show(100)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["## ClusterEvaluator\n###Import from Pyspark"],"metadata":{}},{"cell_type":"code","source":["# > Spark 2.3.0?\nIS_SPARK230 = True\n\nif IS_SPARK230:\n    from pyspark.ml.evaluation import ClusteringEvaluator\n\n    # Evaluate clustering by computing Silhouette score\n    #evaluator =  ClusteringEvaluator().setPredictionCol(\"cluster\").setFeaturesCol(\"features\").setMetricName(\"silhouette\")\n    evaluator = ClusteringEvaluator()\n    #print evaluator.explainParams\n    \n    # Needs Parameters: prediction (of DoubleType values) and label (of float or double values)\n    silhouette = evaluator.evaluate(predictions)\n    # close to 1\n    print(\"Silhouette with squared euclidean distance = \" + str(silhouette))\nelse:\n    # Previous Spark: Evaluate clustering by computing Within Set Sum of Squared Errors.\n    wssse = model.computeCost(train)\n    print(\"Within Set Sum of Squared Errors = \" + str(wssse))"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["# Shows the result.\ncenters = model.clusterCenters()\nprint(\"Cluster Centers: \")\nfor center in centers:\n    print(center)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["# Look at the features of each cluster\n\n# define dictionary\ncustomerCluster = {}\nfor i in range(0,knum):\n    # Group by Cluster that is prediction\n    tmp = predictions.select(\"Tag\", \"OwnerUserId\", \"CreationDate\", \"ParentId\", \"Score\", \\\n                                        \"IsAcceptedAnswer_Indexed\", \"Body\")\\\n                                    .where(\"prediction =\" +  str(i))\n    customerCluster[str(i)]= tmp\n    print \"Cluster\"+str(i)\n    customerCluster[str(i)].show(5)"],"metadata":{},"outputs":[],"execution_count":18}],"metadata":{"name":"R Trial1","notebookId":763084634160242},"nbformat":4,"nbformat_minor":0}
